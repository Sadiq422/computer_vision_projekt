## ğŸš€ **Computer Vision Projekt: CIFAR-10 Klassifikation mit Transfer Learning**

## ğŸ“‹ **ProjektÃ¼bersicht**

Dieses Projekt implementiert eine **Bildklassifikations-Pipeline** fÃ¼r den CIFAR-10-Datensatz unter Verwendung von **Transfer Learning mit ResNet50**. Das Ziel ist es, 10 verschiedene Objektklassen in 32x32 Pixel groÃŸen RGB-Bildern zu klassifizieren.

**ğŸ”— Projekt in Google- Drive:** https://drive

---

## ğŸ¯ **Projektziele**

1. **Datenvorverarbeitung** des CIFAR-10-Datensatzes
2. **Implementierung** eines Transfer-Learning-Ansatzes mit ResNet50
3. **Training und Fine-Tuning** eines benutzerdefinierten Klassifikationskopfes
4. **Evaluierung** der Modellperformance
5. **Dokumentation** aller Schritte und Erkenntnisse

---

## ğŸ“Š **Datensatz: CIFAR-10**

- **60.000 Bilder** (50.000 Training, 10.000 Test)
- **32x32 Pixel** AuflÃ¶sung
- **3 FarbkanÃ¤le** (RGB)
- **10 Klassen**:
  - âœˆï¸ Flugzeug
  - ğŸš— Automobil  
  - ğŸ¦ Vogel
  - ğŸ± Katze
  - ğŸ¦Œ Hirsch
  - ğŸ• Hund
  - ğŸ¸ Frosch
  - ğŸ´ Pferd
  - ğŸš¢ Schiff
  - ğŸšš Lastwagen

**Projektbegrenzung:** 10.000 Trainingsbilder fÃ¼r kÃ¼rzere Trainingszeiten.

---

## ğŸ—ï¸ **Technischer Stack**

### ğŸ“š Hauptbibliotheken
- **TensorFlow 2.x** & **Keras** - Deep Learning Framework
- **ResNet50** - Vortrainiertes CNN fÃ¼r Transfer Learning
- **NumPy** - Numerische Berechnungen
- **Matplotlib** & **Seaborn** - Visualisierung
- **Scikit-learn** - Metriken und Evaluation
- **Pandas** - Datenanalyse

### â˜ï¸ Plattform
- **Google Colab** - Cloud-basierte Entwicklung
- **Google Drive** - Datenspeicherung
- **GPU/TPU Beschleunigung** - Schnelleres Training

---

## ğŸ“ **Projektstruktur**

### Ordner-Hierarchie


````

ComputerVisionProjekt/
â”œâ”€â”€ 1_Download/ # Rohdaten des CIFAR-10 Datensatzes
â”œâ”€â”€ 2_Data_Preprocessing/ # Vorverarbeitete Daten fÃ¼r ResNet50
â”œâ”€â”€ 3_Model_Architecture/ # Modellarchitektur und Konfiguration
â”œâ”€â”€ 4_Training_Head/ # Training des benutzerdefinierten Kopfes
â”œâ”€â”€ 5_Fine_Tuning/ # Fine-Tuning des Basismodells
â”œâ”€â”€ 6_Evaluation/ # Evaluierungsmetriken und Ergebnisse
â”œâ”€â”€ 7_Results/ # Finale Ergebnisse und Modelle
â””â”€â”€ 8_Visualizations/ # Grafiken und Visualisierungen

````




**Alle Daten werden automatisch in deinem Google Drive gespeichert!**

---

## ğŸ”„ Arbeitsablauf im Notebook

### **Phase 1: Setup & Daten** âœ…
1. **Google Drive verbinden** - Persistente Datenspeicherung
2. **Bibliotheken installieren** - TensorFlow, NumPy, Matplotlib, etc.
3. **CIFAR-10 laden** - 10.000 Samples fÃ¼r Training
4. **Daten speichern** - Automatisch in Google Drive

### **Phase 2: Vorverarbeitung** âœ…
1. **Normalisierung** - Bilder auf [0, 1] skalieren
2. **One-Hot Encoding** - Labels fÃ¼r Keras vorbereiten
3. **ResNet50 Preprocessing** - `preprocess_input()` anwenden
4. **Visualisierung** - Beispieldaten anzeigen

### **Phase 3: Modellaufbau** âœ…
1. **ResNet50 Basismodell** - Mit ImageNet Gewichten laden
2. **Custom Head Design** - Dense Layers mit Dropout/BatchNorm
3. **Modell kompilieren** - Adam Optimizer, Categorical Crossentropy

### **Phase 4: Training** ğŸ‹ï¸
1. **Head Training (10 Epochen)** - Nur Custom Layers trainieren
2. **Fine-Tuning (10 Epochen)** - Basismodell mit trainieren
3. **Callbacks** - EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

### **Phase 5: Evaluation** ğŸ“ˆ
1. **Test Performance** - Accuracy und Loss auf Testdaten
2. **Konfusionsmatrix** - Detailierte Klassifikationsanalyse
3. **Vorhersage-Beispiele** - Richtig/Falsch klassifizierte Bilder

### **Phase 6: Dokumentation** ğŸ“
1. **Training History Plots** - Accuracy/Loss Entwicklung
2. **Modelle speichern** - Bestes Modell als .h5 Datei
3. **Ergebnisvisualisierung** - Alle Grafiken exportieren
4. **Daten sichern** - Alles in Google Drive speichern

---

## ğŸ¯ Wichtige Ergebnisse

### **Training Performance:**
- **Head Training**: ~60-70% Validation Accuracy
- **Fine-Tuning**: ~75-85% Validation Accuracy  
- **Test Accuracy**: Ziel ~80% auf ungesehenen Daten

### **Modellarchitektur:**


### **Technische Details:**
- **Optimizer**: Adam (learning_rate=0.001)
- **Loss**: Categorical Crossentropy
- **Batch Size**: 32
- **Epochen**: 10 + 10
- **Validation Split**: 20%

---

## âš¡ Google Colab Tipps

### **Hardware beschleunigen:**
1. Klicke auf **"Laufzeit"** â†’ **"Laufzeittyp Ã¤ndern"**
2. WÃ¤hle **"GPU"** oder **"TPU"** als Hardwarebeschleuniger
3. Klicke auf **"Speichern"**

### **Bei Performance-Problemen:**
- **Batch Size reduzieren** (z.B. von 32 auf 16)
- **EarlyStopping aktivieren** um Epochen zu sparen
- **Nur 5.000 Samples** statt 10.000 verwenden

### **Daten speichern & laden:**
# python
# Alle Daten sind hier gespeichert:
base_path = "/content/drive/MyDrive/"
